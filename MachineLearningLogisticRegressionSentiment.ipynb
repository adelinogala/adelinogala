{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Overall Goal: The code aims to build, train, evaluate, and deploy a machine learning model for sentiment analysis. It will classify movie reviews as either \"positive\" or \"negative.\"\n",
        "\n",
        "Workflow:\n",
        "\n",
        "Setup and Environment Preparation:\n",
        "Install Libraries:\n",
        "\n",
        "Necessary Python libraries (nltk for natural language processing tasks and scikit-learn for machine learning functionalities) are installed.\n",
        "Import Modules: Relevant modules from these libraries and standard Python libraries (like os for file system interaction, pandas for data manipulation, matplotlib for plotting) are imported.\n",
        "Download NLTK Resources: Specific NLTK resources (punkt for tokenization, stopwords for a list of common English stop words, wordnet for lemmatization, and punkt_tab) are downloaded. These are essential for the text preprocessing steps.\n",
        "\n",
        "Data Acquisition and Loading:\n",
        "Download Dataset:\n",
        "\n",
        "The IMDb movie review dataset is downloaded from a specified URL. This dataset contains 50,000 movie reviews, labeled as positive or negative.\n",
        "Extract Dataset: The downloaded compressed file (.tar.gz) is extracted, making the raw text files of the reviews accessible.\n",
        "Define Data Loading Function (load_data): A custom function is created to read the individual review text files. It iterates through 'pos' (positive) and 'neg' (negative) subdirectories for a given path (e.g., the training set), reads each review file, and stores the text along with its corresponding label ('pos' or 'neg').\n",
        "Load Training Data: The load_data function is used to load the training reviews into a Pandas DataFrame.\n",
        "Label Encoding: The sentiment labels ('pos', 'neg') in the DataFrame are converted into numerical format (1 for 'pos', 0 for 'neg'), as machine learning models typically require numerical input.\n",
        "\n",
        "Text Preprocessing:\n",
        "Initialize Tools:\n",
        "\n",
        "A WordNetLemmatizer (to reduce words to their base or dictionary form) and a set of English stopwords are initialized.\n",
        "Define Preprocessing Function (preprocess_text): A function is defined to clean and normalize the review texts. This function performs:\n",
        "Lowercasing: Converts text to lowercase.\n",
        "Tokenization: Splits text into individual words (tokens).\n",
        "Filtering and Lemmatization: Removes punctuation, non-alphanumeric tokens, and stop words. The remaining words are then lemmatized.\n",
        "Rejoining: The processed tokens are joined back into a single string.\n",
        "Apply Preprocessing: The preprocess_text function is applied to all reviews in the 'text' column of the DataFrame, transforming the raw text into a cleaner, more standardized format.\n",
        "\n",
        "Feature Engineering and Data Splitting:\n",
        "Train-Test Split:\n",
        "\n",
        "The preprocessed dataset (features: 'text', target: 'sentiment') is divided into a training set (used to train the model) and a test set (used to evaluate the trained model's performance on unseen data). Typically, 80% for training and 20% for testing.\n",
        "TF-IDF Vectorization:\n",
        "A TfidfVectorizer is initialized. TF-IDF (Term Frequency-Inverse Document Frequency) converts text data into numerical feature vectors. It gives higher weight to words that are frequent in a specific document but not frequent across all documents.\n",
        "The vectorizer is fit_transformed on the training text data. This means it learns the vocabulary from the training data and then transforms this training text into a TF-IDF matrix.\n",
        "The same fitted vectorizer is then used to transform the test text data, ensuring consistency and preventing data leakage.\n",
        "\n",
        "Model Training:\n",
        "Initialize Model:\n",
        "\n",
        "A LogisticRegression classifier is chosen as the machine learning model. This is a linear model commonly used for binary classification tasks.\n",
        "Train Model: The Logistic Regression model is trained (fit) using the TF-IDF features of the training set (X_train_tfidf) and their corresponding sentiment labels (y_train). The model learns the relationship between the word features and the sentiment.\n",
        "\n",
        "Model Evaluation:\n",
        "Make Predictions:\n",
        "\n",
        "The trained model is used to predict sentiment labels for the TF-IDF features of the unseen test data (X_test_tfidf).\n",
        "Calculate Metrics:\n",
        "Accuracy: The proportion of correctly classified reviews is calculated.\n",
        "Classification Report: A detailed report is generated, showing precision, recall, F1-score, and support for both positive and negative classes.\n",
        "Visualize Performance:\n",
        "Confusion Matrix: A matrix is plotted to visualize the model's performance, showing counts of true positives, true negatives, false positives, and false negatives.\n",
        "ROC Curve and AUC: The Receiver Operating Characteristic (ROC) curve is plotted, and the Area Under the Curve (AUC) is calculated. This helps assess the model's ability to distinguish between positive and negative classes across different probability thresholds.\n",
        "\n",
        "Model Persistence (Saving):\n",
        "\n",
        "The trained Logistic Regression model and the fitted TF-IDF vectorizer are saved to disk using joblib. This allows them to be loaded and reused later without needing to retrain the model or refit the vectorizer from scratch.\n",
        "\n",
        "Prediction on New, Unseen Data:\n",
        "Define Prediction Function (predict_sentiment):\n",
        "\n",
        "A function is created to take a new text review, the saved model, and the saved vectorizer as input.\n",
        "Inside this function:\n",
        "The new text is preprocessed using the same preprocess_text function.\n",
        "The preprocessed text is transformed into TF-IDF features using the loaded vectorizer.\n",
        "The loaded model predicts the sentiment.\n",
        "The function returns \"Positive\" or \"Negative\".\n",
        "Test with Examples: The predict_sentiment function is demonstrated by providing a few sample new reviews and printing their predicted sentiments.\n",
        "\n",
        "Interactive User Interface (using ipywidgets in Colab):\n",
        "Create Widgets:\n",
        "\n",
        "Interactive elements are created:\n",
        "A text input field (widgets.Text) for users to type their review.\n",
        "A \"Send\" button (widgets.Button).\n",
        "An output area (widgets.Output) to display the review and its predicted sentiment.\n",
        "Define Event Handler: A function (on_send_button_clicked) is defined to execute when the button is clicked. This function:\n",
        "Retrieves the review text from the input field.\n",
        "Calls the predict_sentiment function to get the sentiment.\n",
        "Displays the original review and the predicted sentiment in the output area.\n",
        "Clears the input field.\n",
        "Display Interface: The widgets are arranged and displayed in the Colab notebook, providing a simple interactive way to test the sentiment analysis model."
      ],
      "metadata": {
        "id": "rQqPPKmjuRmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHFOkrflg071"
      },
      "outputs": [],
      "source": [
        "# Instalação de bibliotecas necessárias\n",
        "!pip install nltk\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Importação das bibliotecas\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download de recursos do NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')  # Adicionando o download do recurso punkt_tab\n",
        "\n",
        "# Carregamento do conjunto de dados\n",
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "!wget -q {url}\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "\n",
        "# Função para carregar os dados\n",
        "def load_data(path):\n",
        "    data = []\n",
        "    for label in ['pos', 'neg']:\n",
        "        dir_path = f\"{path}/{label}\"\n",
        "        for file in os.listdir(dir_path):\n",
        "            with open(f\"{dir_path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                data.append((text, label))\n",
        "    return pd.DataFrame(data, columns=['text', 'sentiment'])\n",
        "\n",
        "# Carregando os dados\n",
        "df = load_data('aclImdb/train')\n",
        "df['sentiment'] = df['sentiment'].map({'pos': 1, 'neg': 0})\n",
        "\n",
        "# Tokenização e Lemmatização\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Divisão dos dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vetorização TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Avaliação do modelo\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(f\"Acurácia: {accuracy_score(y_test, y_pred)}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xticks([0, 1], ['Negative', 'Positive'])\n",
        "plt.yticks([0, 1], ['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "y_pred_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "import joblib\n",
        "joblib.dump(model, 'logistic_regression_sentiment_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "\n",
        "# Function to test the model on new data\n",
        "def predict_sentiment(text, model, vectorizer):\n",
        "    text = preprocess_text(text)\n",
        "    text_tfidf = vectorizer.transform([text])\n",
        "    prediction = model.predict(text_tfidf)\n",
        "    return 'Positive' if prediction[0] == 1 else 'Negative'\n",
        "\n",
        "# Test the model on new data\n",
        "new_reviews = [\n",
        "    \"This movie was fantastic! I loved every bit of it.\",\n",
        "    \"The film was terrible and boring.\",\n",
        "    \"It was okay, not great but not bad either.\"\n",
        "]\n",
        "\n",
        "for review in new_reviews:\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Predicted Sentiment: {predict_sentiment(review, model, vectorizer)}\\n\")\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Create an output widget to display the conversation log\n",
        "chat_output = widgets.Output()\n",
        "\n",
        "# Create a text input widget for new review entries\n",
        "text_input = widgets.Text(\n",
        "    placeholder='Digite sua review para análise de sentimento...',\n",
        "    description='Review:',\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "\n",
        "# Create a button widget to submit the review\n",
        "send_button = widgets.Button(\n",
        "    description='Enviar',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Define the event handler for the send button\n",
        "def on_send_button_clicked(b):\n",
        "    review = text_input.value.strip()\n",
        "    if review:\n",
        "        with chat_output:\n",
        "            # Display the entered review\n",
        "            print(\"Review:\", review)\n",
        "            # Get the predicted sentiment using your predict_sentiment function\n",
        "            sentiment = predict_sentiment(review, model, vectorizer)\n",
        "            print(\"Predicted Sentiment:\", sentiment)\n",
        "            print(\"-\" * 40)\n",
        "    # Clear the input field after processing\n",
        "    text_input.value = \"\"\n",
        "\n",
        "# Attach the event handler to the button\n",
        "send_button.on_click(on_send_button_clicked)\n",
        "\n",
        "# Arrange the widgets vertically and display the chat interface\n",
        "chat_interface = widgets.VBox([text_input, send_button, chat_output])\n",
        "display(chat_interface)\n"
      ]
    }
  ]
}